Help on package gym:

NAME
    gym

PACKAGE CONTENTS
    core
    envs (package)
    error
    logger
    spaces (package)
    utils (package)
    version
    wrappers (package)

CLASSES
    builtins.object
        gym.core.Env
            gym.core.Wrapper
        gym.core.Space
    
    class Env(builtins.object)
     |  The main OpenAI Gym class. It encapsulates an environment with
     |  arbitrary behind-the-scenes dynamics. An environment can be
     |  partially or fully observed.
     |  
     |  The main API methods that users of this class need to know are:
     |  
     |      step
     |      reset
     |      render
     |      close
     |      seed
     |  
     |  And set the following attributes:
     |  
     |      action_space: The Space object corresponding to valid actions
     |      observation_space: The Space object corresponding to valid observations
     |      reward_range: A tuple corresponding to the min and max possible rewards
     |  
     |  Note: a default reward range set to [-inf,+inf] already exists. Set it if you want a narrower range.
     |  
     |  The methods are accessed publicly as "step", "reset", etc.. The
     |  non-underscored versions are wrapper methods to which we may add
     |  functionality over time.
     |  
     |  Methods defined here:
     |  
     |  __str__(self)
     |      Return str(self).
     |  
     |  close(self)
     |      Override _close in your subclass to perform any necessary cleanup.
     |      
     |      Environments will automatically close() themselves when
     |      garbage collected or when the program exits.
     |  
     |  render(self, mode='human')
     |      Renders the environment.
     |      
     |      The set of supported modes varies per environment. (And some
     |      environments do not support rendering at all.) By convention,
     |      if mode is:
     |      
     |      - human: render to the current display or terminal and
     |        return nothing. Usually for human consumption.
     |      - rgb_array: Return an numpy.ndarray with shape (x, y, 3),
     |        representing RGB values for an x-by-y pixel image, suitable
     |        for turning into a video.
     |      - ansi: Return a string (str) or StringIO.StringIO containing a
     |        terminal-style text representation. The text can include newlines
     |        and ANSI escape sequences (e.g. for colors).
     |      
     |      Note:
     |          Make sure that your class's metadata 'render.modes' key includes
     |            the list of supported modes. It's recommended to call super()
     |            in implementations to use the functionality of this method.
     |      
     |      Args:
     |          mode (str): the mode to render with
     |          close (bool): close all open renderings
     |      
     |      Example:
     |      
     |      class MyEnv(Env):
     |          metadata = {'render.modes': ['human', 'rgb_array']}
     |      
     |          def render(self, mode='human'):
     |              if mode == 'rgb_array':
     |                  return np.array(...) # return RGB frame suitable for video
     |              elif mode is 'human':
     |                  ... # pop up a window and render
     |              else:
     |                  super(MyEnv, self).render(mode=mode) # just raise an exception
     |  
     |  reset(self)
     |      Resets the state of the environment and returns an initial observation.
     |      
     |      Returns: observation (object): the initial observation of the
     |          space.
     |  
     |  seed(self, seed=None)
     |      Sets the seed for this env's random number generator(s).
     |      
     |      Note:
     |          Some environments use multiple pseudorandom number generators.
     |          We want to capture all such seeds used in order to ensure that
     |          there aren't accidental correlations between multiple generators.
     |      
     |      Returns:
     |          list<bigint>: Returns the list of seeds used in this env's random
     |            number generators. The first value in the list should be the
     |            "main" seed, or the value which a reproducer should pass to
     |            'seed'. Often, the main seed equals the provided 'seed', but
     |            this won't be true if seed=None, for example.
     |  
     |  step(self, action)
     |      Run one timestep of the environment's dynamics. When end of
     |      episode is reached, you are responsible for calling `reset()`
     |      to reset this environment's state.
     |      
     |      Accepts an action and returns a tuple (observation, reward, done, info).
     |      
     |      Args:
     |          action (object): an action provided by the environment
     |      
     |      Returns:
     |          observation (object): agent's observation of the current environment
     |          reward (float) : amount of reward returned after previous action
     |          done (boolean): whether the episode has ended, in which case further step() calls will return undefined results
     |          info (dict): contains auxiliary diagnostic information (helpful for debugging, and sometimes learning)
     |  
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |  
     |  __dict__
     |      dictionary for instance variables (if defined)
     |  
     |  __weakref__
     |      list of weak references to the object (if defined)
     |  
     |  unwrapped
     |      Completely unwrap this env.
     |      
     |      Returns:
     |          gym.Env: The base non-wrapped gym.Env instance
     |  
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |  
     |  action_space = None
     |  
     |  metadata = {'render.modes': []}
     |  
     |  observation_space = None
     |  
     |  reward_range = (-inf, inf)
     |  
     |  spec = None
    
    class Space(builtins.object)
     |  Defines the observation and action spaces, so you can write generic
     |  code that applies to any Env. For example, you can choose a random
     |  action.
     |  
     |  Methods defined here:
     |  
     |  __init__(self, shape=None, dtype=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |  
     |  contains(self, x)
     |      Return boolean specifying if x is a valid
     |      member of this space
     |  
     |  from_jsonable(self, sample_n)
     |      Convert a JSONable data type to a batch of samples from this space.
     |  
     |  sample(self)
     |      Uniformly randomly sample a random element of this space
     |  
     |  to_jsonable(self, sample_n)
     |      Convert a batch of samples from this space to a JSONable data type.
     |  
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |  
     |  __dict__
     |      dictionary for instance variables (if defined)
     |  
     |  __weakref__
     |      list of weak references to the object (if defined)
    
    class Wrapper(Env)
     |  The main OpenAI Gym class. It encapsulates an environment with
     |  arbitrary behind-the-scenes dynamics. An environment can be
     |  partially or fully observed.
     |  
     |  The main API methods that users of this class need to know are:
     |  
     |      step
     |      reset
     |      render
     |      close
     |      seed
     |  
     |  And set the following attributes:
     |  
     |      action_space: The Space object corresponding to valid actions
     |      observation_space: The Space object corresponding to valid observations
     |      reward_range: A tuple corresponding to the min and max possible rewards
     |  
     |  Note: a default reward range set to [-inf,+inf] already exists. Set it if you want a narrower range.
     |  
     |  The methods are accessed publicly as "step", "reset", etc.. The
     |  non-underscored versions are wrapper methods to which we may add
     |  functionality over time.
     |  
     |  Method resolution order:
     |      Wrapper
     |      Env
     |      builtins.object
     |  
     |  Methods defined here:
     |  
     |  __init__(self, env)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |  
     |  __repr__(self)
     |      Return repr(self).
     |  
     |  __str__(self)
     |      Return str(self).
     |  
     |  close(self)
     |      Override _close in your subclass to perform any necessary cleanup.
     |      
     |      Environments will automatically close() themselves when
     |      garbage collected or when the program exits.
     |  
     |  compute_reward(self, achieved_goal, desired_goal, info)
     |  
     |  render(self, mode='human')
     |      Renders the environment.
     |      
     |      The set of supported modes varies per environment. (And some
     |      environments do not support rendering at all.) By convention,
     |      if mode is:
     |      
     |      - human: render to the current display or terminal and
     |        return nothing. Usually for human consumption.
     |      - rgb_array: Return an numpy.ndarray with shape (x, y, 3),
     |        representing RGB values for an x-by-y pixel image, suitable
     |        for turning into a video.
     |      - ansi: Return a string (str) or StringIO.StringIO containing a
     |        terminal-style text representation. The text can include newlines
     |        and ANSI escape sequences (e.g. for colors).
     |      
     |      Note:
     |          Make sure that your class's metadata 'render.modes' key includes
     |            the list of supported modes. It's recommended to call super()
     |            in implementations to use the functionality of this method.
     |      
     |      Args:
     |          mode (str): the mode to render with
     |          close (bool): close all open renderings
     |      
     |      Example:
     |      
     |      class MyEnv(Env):
     |          metadata = {'render.modes': ['human', 'rgb_array']}
     |      
     |          def render(self, mode='human'):
     |              if mode == 'rgb_array':
     |                  return np.array(...) # return RGB frame suitable for video
     |              elif mode is 'human':
     |                  ... # pop up a window and render
     |              else:
     |                  super(MyEnv, self).render(mode=mode) # just raise an exception
     |  
     |  reset(self, **kwargs)
     |      Resets the state of the environment and returns an initial observation.
     |      
     |      Returns: observation (object): the initial observation of the
     |          space.
     |  
     |  seed(self, seed=None)
     |      Sets the seed for this env's random number generator(s).
     |      
     |      Note:
     |          Some environments use multiple pseudorandom number generators.
     |          We want to capture all such seeds used in order to ensure that
     |          there aren't accidental correlations between multiple generators.
     |      
     |      Returns:
     |          list<bigint>: Returns the list of seeds used in this env's random
     |            number generators. The first value in the list should be the
     |            "main" seed, or the value which a reproducer should pass to
     |            'seed'. Often, the main seed equals the provided 'seed', but
     |            this won't be true if seed=None, for example.
     |  
     |  step(self, action)
     |      Run one timestep of the environment's dynamics. When end of
     |      episode is reached, you are responsible for calling `reset()`
     |      to reset this environment's state.
     |      
     |      Accepts an action and returns a tuple (observation, reward, done, info).
     |      
     |      Args:
     |          action (object): an action provided by the environment
     |      
     |      Returns:
     |          observation (object): agent's observation of the current environment
     |          reward (float) : amount of reward returned after previous action
     |          done (boolean): whether the episode has ended, in which case further step() calls will return undefined results
     |          info (dict): contains auxiliary diagnostic information (helpful for debugging, and sometimes learning)
     |  
     |  ----------------------------------------------------------------------
     |  Class methods defined here:
     |  
     |  class_name() from builtins.type
     |  
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |  
     |  spec
     |  
     |  unwrapped
     |      Completely unwrap this env.
     |      
     |      Returns:
     |          gym.Env: The base non-wrapped gym.Env instance
     |  
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |  
     |  env = None
     |  
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from Env:
     |  
     |  __dict__
     |      dictionary for instance variables (if defined)
     |  
     |  __weakref__
     |      list of weak references to the object (if defined)
     |  
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from Env:
     |  
     |  action_space = None
     |  
     |  metadata = {'render.modes': []}
     |  
     |  observation_space = None
     |  
     |  reward_range = (-inf, inf)

FUNCTIONS
    make(id)
    
    spec(id)

DATA
    __all__ = ['Env', 'Space', 'Wrapper', 'make', 'spec', 'wrappers']

VERSION
    0.10.5

FILE
    c:\users\joonw\venv\expython\lib\site-packages\gym\__init__.py


